{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5d830e-ddcb-466d-b2e6-ec9afd3be47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d82be4-0f45-46a6-8920-e0185400ac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集输入形状: (14881, 336, 16)\n",
      "训练集目标形状: (14881, 240)\n",
      "测试集（短期）输入形状: (1825, 336, 16)\n",
      "测试集（短期）目标形状: (1825, 240)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def load_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    加载训练集和测试集数据，并返回目标变量和特征。\n",
    "    \"\"\"\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    train_cnt = train_data['cnt'].values # 提取目标变量\n",
    "    train_features = train_data.iloc[:, 1:]  # 提取特征列\n",
    "\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    test_cnt = test_data['cnt'].values  # 提取目标变量\n",
    "    test_features = test_data.iloc[:, 1:]  # 提取特征列\n",
    "    \n",
    "    return train_features, train_cnt, test_features, test_cnt\n",
    "\n",
    "def create_sequences(features, targets, input_length, output_length):\n",
    "    \"\"\"\n",
    "    根据滑动窗口生成输入序列和目标序列。\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(targets) - input_length - output_length + 1):\n",
    "        X.append(features[i:i + input_length+ output_length].values)\n",
    "        y.append(targets[i + input_length:i + input_length + output_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 加载数据\n",
    "train_features, train_cnt, test_features, test_cnt = load_data('train_data.csv', 'test_data.csv')\n",
    "\n",
    "# 定义滑动窗口长度\n",
    "input_length = 96\n",
    "output_length_short = 96  # 短期预测\n",
    "output_length_long = 240  # 长期预测\n",
    "\n",
    "# 生成训练数据和测试数据\n",
    "X_train, y_train = create_sequences(train_features, train_cnt, input_length, output_length_long)\n",
    "X_test, y_test = create_sequences(test_features, test_cnt, input_length, output_length_long)\n",
    "\n",
    "# 检查生成数据形状\n",
    "print(\"训练集输入形状:\", X_train.shape)\n",
    "print(\"训练集目标形状:\", y_train.shape)\n",
    "print(\"测试集（短期）输入形状:\", X_test.shape)\n",
    "print(\"测试集（短期）目标形状:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f308fb69-814f-4ad6-ab0c-bd844b1ae89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14881, 336)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d2de1b-5a60-45c6-b984-811410b373a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datasets import Dataset, Value, Sequence, Features\n",
    "\n",
    "data = {\n",
    "    'start': pd.to_datetime(X_train[:,0,0]),\n",
    "    'target':X_train[:,:,-1] ,  # Sequence of float32\n",
    "    \"feat_static_cat\": [[0] for _ in range(X_train.shape[0])],\n",
    "    \"feat_dynamic_real\": X_train[:,:,1:-1],    # 动态实值特征\n",
    "    \"item_id\": [f\"T{i}\" for i in range(X_train.shape[0])],    \n",
    "}\n",
    "               \n",
    "features = Features({\n",
    "    'start': Value(dtype='timestamp[s]'),\n",
    "    'target': Sequence(feature=Value(dtype='float32')),\n",
    "    'feat_static_cat': Sequence(feature=Value(dtype='uint64')),\n",
    "    'feat_dynamic_real': Sequence(feature=Sequence(feature=Value(dtype='float32'))),\n",
    "    'item_id': Value(dtype='string'),\n",
    "})\n",
    "# 转换为 Hugging Face 数据集\n",
    "train_dataset = Dataset.from_dict(data, features=features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2261e6cc-537c-414e-b36a-441cfce4a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'start': pd.to_datetime(X_test[:,0,0]),\n",
    "    'target':X_test[:,:,-1] ,  # Sequence of float32\n",
    "    \"feat_static_cat\": [[0] for _ in range(X_test.shape[0])],\n",
    "    \"feat_dynamic_real\": X_test[:,:,1:-1],    # 动态实值特征\n",
    "    \"item_id\": [f\"T{i}\" for i in range(X_test.shape[0])],    \n",
    "}\n",
    "               \n",
    "features = Features({\n",
    "    'start': Value(dtype='timestamp[s]'),\n",
    "    'target': Sequence(feature=Value(dtype='float32')),\n",
    "    'feat_static_cat': Sequence(feature=Value(dtype='uint64')),\n",
    "    'feat_dynamic_real': Sequence(feature=Sequence(feature=Value(dtype='float32'))),\n",
    "    'item_id': Value(dtype='string'),\n",
    "})\n",
    "# 转换为 Hugging Face 数据集\n",
    "test_dataset = Dataset.from_dict(data, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5c57e8-a783-4c61-bf59-d2a2d55ffdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': Value(dtype='timestamp[s]', id=None), 'target': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), 'feat_static_cat': Sequence(feature=Value(dtype='uint64', id=None), length=-1, id=None), 'feat_dynamic_real': Sequence(feature=Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), length=-1, id=None), 'item_id': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7162595d-d592-4492-bd5a-aed575e21d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387cd22e-96a4-49ba-814e-f10b2558f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "@lru_cache(10_000)\n",
    "def convert_to_pandas_period(date, freq):\n",
    "    return pd.Period(date, freq)\n",
    "\n",
    "def transform_start_field(batch, freq):\n",
    "    batch[\"start\"] = [convert_to_pandas_period(date, freq) for date in batch[\"start\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba32b7db-5f1f-435d-abb7-d02e643d359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
    "test_dataset.set_transform(partial(transform_start_field, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e624ab9-4a99-4fef-9cd4-b38952f91265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 23, 24, 25, 47, 48, 49, 71, 72, 73, 95, 96, 97, 119, 120, 121, 143, 144, 145, 167, 168, 169, 335, 336, 337, 503, 504, 505, 671, 672, 673, 719, 720, 721]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.time_feature import get_lags_for_frequency\n",
    "\n",
    "lags_sequence = get_lags_for_frequency(freq)\n",
    "print(lags_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3726e42c-d139-4aa9-b924-ba225f975faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function hour_of_day at 0x000002618E231310>, <function day_of_week at 0x000002618E231430>, <function day_of_month at 0x000002618E231550>, <function day_of_year at 0x000002618E231670>]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.time_feature import time_features_from_frequency_str\n",
    "\n",
    "time_features = time_features_from_frequency_str(freq)\n",
    "print(time_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6da444-b3c7-4fc2-a273-1d3c73e9f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.48.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad08348-b34f-4438-883b-268b07459b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "551a0dca-085e-4d34-95b4-dc5d9e0d640e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
    "\n",
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=240,\n",
    "    # context length:\n",
    "    context_length=96,\n",
    "    # lags coming from helper given the freq:\n",
    "    lags_sequence=lags_sequence,\n",
    "    # we'll add 2 time features (\"month of year\" and \"age\", see further):\n",
    "    num_time_features=len(time_features) + 1,\n",
    "    # we have a single static categorical feature, namely time series ID:\n",
    "    num_static_categorical_features=1,\n",
    "    # it has 366 possible values:\n",
    "    cardinality=[len(train_dataset)],\n",
    "    # the model will learn an embedding of size 2 for each of the 366 possible values:\n",
    "    embedding_dimension=[2],\n",
    "    \n",
    "    # transformer params:\n",
    "    encoder_layers=4,\n",
    "    decoder_layers=4,\n",
    "    d_model=32,\n",
    ")\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18570e67-f8c7-4cd1-94e8-43a7d703183a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'student_t'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.distribution_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701349c7-d14d-4c3b-b1eb-0fc571e8a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.time_feature import (\n",
    "    time_features_from_frequency_str,\n",
    "    TimeFeature,\n",
    "    get_lags_for_frequency,\n",
    ")\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.transform import (\n",
    "    AddAgeFeature,\n",
    "    AddObservedValuesIndicator,\n",
    "    AddTimeFeatures,\n",
    "    AsNumpyArray,\n",
    "    Chain,\n",
    "    ExpectedNumInstanceSampler,\n",
    "    InstanceSplitter,\n",
    "    RemoveFields,\n",
    "    SelectFields,\n",
    "    SetField,\n",
    "    TestSplitSampler,\n",
    "    Transformation,\n",
    "    ValidationSplitSampler,\n",
    "    VstackFeatures,\n",
    "    RenameFields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf2bb7f8-0681-42fa-be8f-338448115770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
    "    remove_field_names = []\n",
    "    if config.num_static_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
    "    if config.num_dynamic_real_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
    "    if config.num_static_categorical_features == 0:\n",
    "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
    "\n",
    "    # a bit like torchvision.transforms.Compose\n",
    "    return Chain(\n",
    "        # step 1: remove static/dynamic fields if not specified\n",
    "        [RemoveFields(field_names=remove_field_names)]\n",
    "        # step 2: convert the data to NumPy (potentially not needed)\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_CAT,\n",
    "                    expected_ndim=1,\n",
    "                    dtype=int,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + (\n",
    "            [\n",
    "                AsNumpyArray(\n",
    "                    field=FieldName.FEAT_STATIC_REAL,\n",
    "                    expected_ndim=1,\n",
    "                )\n",
    "            ]\n",
    "            if config.num_static_real_features > 0\n",
    "            else []\n",
    "        )\n",
    "        + [\n",
    "            AsNumpyArray(\n",
    "                field=FieldName.TARGET,\n",
    "                # we expect an extra dim for the multivariate case:\n",
    "                expected_ndim=1 if config.input_size == 1 else 2,\n",
    "            ),\n",
    "            # step 3: handle the NaN's by filling in the target with zero\n",
    "            # and return the mask (which is in the observed values)\n",
    "            # true for observed values, false for nan's\n",
    "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
    "            # see loss_weights inside the xxxForPrediction model\n",
    "            AddObservedValuesIndicator(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.OBSERVED_VALUES,\n",
    "            ),\n",
    "            # step 4: add temporal features based on freq of the dataset\n",
    "            # month of year in the case when freq=\"M\"\n",
    "            # these serve as positional encodings\n",
    "            AddTimeFeatures(\n",
    "                start_field=FieldName.START,\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                time_features=time_features_from_frequency_str(freq),\n",
    "                pred_length=config.prediction_length,\n",
    "            ),\n",
    "            # step 5: add another temporal feature (just a single number)\n",
    "            # tells the model where in its life the value of the time series is,\n",
    "            # sort of a running counter\n",
    "            AddAgeFeature(\n",
    "                target_field=FieldName.TARGET,\n",
    "                output_field=FieldName.FEAT_AGE,\n",
    "                pred_length=config.prediction_length,\n",
    "                log_scale=True,\n",
    "            ),\n",
    "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
    "            VstackFeatures(\n",
    "                output_field=FieldName.FEAT_TIME,\n",
    "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
    "                + (\n",
    "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
    "                    if config.num_dynamic_real_features > 0\n",
    "                    else []\n",
    "                ),\n",
    "            ),\n",
    "            # step 7: rename to match HuggingFace names\n",
    "            RenameFields(\n",
    "                mapping={\n",
    "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
    "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
    "                    FieldName.FEAT_TIME: \"time_features\",\n",
    "                    FieldName.TARGET: \"values\",\n",
    "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbddf329-5822-41ec-ac1d-1f39452edbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.transform.sampler import InstanceSampler\n",
    "from typing import Optional\n",
    "\n",
    "def create_instance_splitter(\n",
    "    config: PretrainedConfig,\n",
    "    mode: str,\n",
    "    train_sampler: Optional[InstanceSampler] = None,\n",
    "    validation_sampler: Optional[InstanceSampler] = None,\n",
    ") -> Transformation:\n",
    "    assert mode in [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "    instance_sampler = {\n",
    "        \"train\": train_sampler\n",
    "        or ExpectedNumInstanceSampler(\n",
    "            num_instances=1.0, min_future=config.prediction_length\n",
    "        ),\n",
    "        \"validation\": validation_sampler\n",
    "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
    "        \"test\": TestSplitSampler(),\n",
    "    }[mode]\n",
    "\n",
    "    return InstanceSplitter(\n",
    "        target_field=\"values\",\n",
    "        is_pad_field=FieldName.IS_PAD,\n",
    "        start_field=FieldName.START,\n",
    "        forecast_start_field=FieldName.FORECAST_START,\n",
    "        instance_sampler=instance_sampler,\n",
    "        past_length=config.context_length + max(config.lags_sequence),\n",
    "        future_length=config.prediction_length,\n",
    "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eecd83b6-89db-4e71-9fdf-49be2a983bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from gluonts.itertools import Cached, Cyclic\n",
    "from gluonts.dataset.loader import as_stacked_batches\n",
    "\n",
    "\n",
    "def create_train_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    num_batches_per_epoch: int,\n",
    "    shuffle_buffer_length: Optional[int] = None,\n",
    "    cache_data: bool = True,\n",
    "    **kwargs,\n",
    ") -> Iterable:\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
    "        \"future_values\",\n",
    "        \"future_observed_mask\",\n",
    "    ]\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=True)\n",
    "    if cache_data:\n",
    "        transformed_data = Cached(transformed_data)\n",
    "\n",
    "    # we initialize a Training instance\n",
    "    instance_splitter = create_instance_splitter(config, \"train\")\n",
    "\n",
    "    # the instance splitter will sample a window of\n",
    "    # context length + lags + prediction length (from the 366 possible transformed time series)\n",
    "    # randomly from within the target time series and return an iterator.\n",
    "    stream = Cyclic(transformed_data).stream()\n",
    "    training_instances = instance_splitter.apply(\n",
    "        stream, is_train=True\n",
    "    )\n",
    "    \n",
    "    return as_stacked_batches(\n",
    "        training_instances,\n",
    "        batch_size=batch_size,\n",
    "        shuffle_buffer_length=shuffle_buffer_length,\n",
    "        field_names=TRAINING_INPUT_NAMES,\n",
    "        output_type=torch.tensor,\n",
    "        num_batches_per_epoch=num_batches_per_epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42464404-b45f-405c-a5fd-cfe72475f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataloader(\n",
    "    config: PretrainedConfig,\n",
    "    freq,\n",
    "    data,\n",
    "    batch_size: int,\n",
    "    **kwargs,\n",
    "):\n",
    "    PREDICTION_INPUT_NAMES = [\n",
    "        \"past_time_features\",\n",
    "        \"past_values\",\n",
    "        \"past_observed_mask\",\n",
    "        \"future_time_features\",\n",
    "    ]\n",
    "    if config.num_static_categorical_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
    "\n",
    "    if config.num_static_real_features > 0:\n",
    "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
    "\n",
    "    transformation = create_transformation(freq, config)\n",
    "    transformed_data = transformation.apply(data, is_train=False)\n",
    "\n",
    "    # we create a Test Instance splitter which will sample the very last\n",
    "    # context window seen during training only for the encoder.\n",
    "    instance_sampler = create_instance_splitter(config, \"test\")\n",
    "\n",
    "    # we apply the transformations in test mode\n",
    "    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n",
    "    \n",
    "    return as_stacked_batches(\n",
    "        testing_instances,\n",
    "        batch_size=batch_size,\n",
    "        output_type=torch.tensor,\n",
    "        field_names=PREDICTION_INPUT_NAMES,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47b6c950-bb97-458c-b5cf-47a25495eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_train_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=train_dataset,\n",
    "    batch_size=256,\n",
    "    num_batches_per_epoch=100,\n",
    ")\n",
    "\n",
    "test_dataloader = create_test_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=test_dataset,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0909154-ea8a-4f2c-83fe-4d0639aa68bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past_time_features torch.Size([256, 817, 5]) torch.FloatTensor\n",
      "past_values torch.Size([256, 817]) torch.FloatTensor\n",
      "past_observed_mask torch.Size([256, 817]) torch.FloatTensor\n",
      "future_time_features torch.Size([256, 240, 5]) torch.FloatTensor\n",
      "static_categorical_features torch.Size([256, 1]) torch.LongTensor\n",
      "future_values torch.Size([256, 240]) torch.FloatTensor\n",
      "future_observed_mask torch.Size([256, 240]) torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6e75820-11d5-4905-b0e8-221b5e0d0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform forward pass\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"]\n",
    "    if config.num_static_categorical_features > 0\n",
    "    else None,\n",
    "    static_real_features=batch[\"static_real_features\"]\n",
    "    if config.num_static_real_features > 0\n",
    "    else None,\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    "    future_observed_mask=batch[\"future_observed_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "968fa2fb-4a95-4201-bb38-ce04008f2e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.765669345855713\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss:\", outputs.loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd015034-d289-438a-a532-9824180bc2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7786407470703125\n",
      "6.536793231964111\n",
      "5.587109565734863\n",
      "5.519179344177246\n",
      "5.762878894805908\n",
      "5.159056663513184\n",
      "5.635081768035889\n",
      "4.9649658203125\n",
      "5.614075660705566\n",
      "5.147049903869629\n",
      "5.3787946701049805\n",
      "5.623485088348389\n",
      "5.454380989074707\n",
      "5.292891502380371\n",
      "5.363819599151611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from accelerate import Accelerator\n",
    "from torch.optim import AdamW\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "\n",
    "model, optimizer, train_dataloader = accelerator.prepare(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(15):\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "            if config.num_static_categorical_features > 0\n",
    "            else None,\n",
    "            static_real_features=batch[\"static_real_features\"].to(device)\n",
    "            if config.num_static_real_features > 0\n",
    "            else None,\n",
    "            past_time_features=batch[\"past_time_features\"].to(device),\n",
    "            past_values=batch[\"past_values\"].to(device),\n",
    "            future_time_features=batch[\"future_time_features\"].to(device),\n",
    "            future_values=batch[\"future_values\"].to(device),\n",
    "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backpropagation\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45f8ba25-d010-4bb5-affd-d4ae187155a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "forecasts = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    outputs = model.generate(\n",
    "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "        if config.num_static_categorical_features > 0\n",
    "        else None,\n",
    "        static_real_features=batch[\"static_real_features\"].to(device)\n",
    "        if config.num_static_real_features > 0\n",
    "        else None,\n",
    "        past_time_features=batch[\"past_time_features\"].to(device),\n",
    "        past_values=batch[\"past_values\"].to(device),\n",
    "        future_time_features=batch[\"future_time_features\"].to(device),\n",
    "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "    )\n",
    "    forecasts.append(outputs.sequences.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b85acbec-901e-44e2-802c-01e9ec67d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 100, 240)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e11db592-1d7a-49b1-917b-f86c39f830d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 100, 240)\n"
     ]
    }
   ],
   "source": [
    "forecasts = np.vstack(forecasts)\n",
    "print(forecasts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd0c6947-8f51-4153-8d33-7a403e66c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from gluonts.time_feature import get_seasonality\n",
    "\n",
    "mase_metric = load(\"evaluate-metric/mase\")\n",
    "smape_metric = load(\"evaluate-metric/smape\")\n",
    "\n",
    "forecast_median = np.median(forecasts, 1)\n",
    "\n",
    "mase_metrics = []\n",
    "smape_metrics = []\n",
    "for item_id, ts in enumerate(test_dataset):\n",
    "    training_data = ts[\"target\"][:-240]\n",
    "    ground_truth = ts[\"target\"][-240:]\n",
    "    mase = mase_metric.compute(\n",
    "        predictions=forecast_median[item_id], \n",
    "        references=np.array(ground_truth), \n",
    "        training=np.array(training_data), \n",
    "        periodicity=get_seasonality(freq))\n",
    "    mase_metrics.append(mase[\"mase\"])\n",
    "    \n",
    "    smape = smape_metric.compute(\n",
    "        predictions=forecast_median[item_id], \n",
    "        references=np.array(ground_truth), \n",
    "    )\n",
    "    smape_metrics.append(smape[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30ba0b0d-3566-4241-b661-b987aa1c881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASE: 1.8424619730637704\n"
     ]
    }
   ],
   "source": [
    "print(f\"MASE: {np.mean(mase_metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14577865-5afa-4bf0-94e5-d87dfbffe3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sMAPE: 0.8184760431047806\n"
     ]
    }
   ],
   "source": [
    "print(f\"sMAPE: {np.mean(smape_metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "da86314b-9c27-48bd-8343-012ae1ff6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth=X_test[:,:-96,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5262aa-e8a8-45d1-87b0-48437616863e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
